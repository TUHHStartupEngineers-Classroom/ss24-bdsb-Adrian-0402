[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes\n\n\nnumbers &lt;- 1:1000\n\n# This will print the first 10 elements of the vector numbers\nnumbers[1:10]\n\n# This will plot a histogram of 100 random elements of the vector numbers\nhist(sample(numbers, 100, replace = T))"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing."
  },
  {
    "objectID": "content/02_notes/05_class_notes.html#header-2",
    "href": "content/02_notes/05_class_notes.html#header-2",
    "title": "Class Notes",
    "section": "Header 2",
    "text": "Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "1 Wrangling with Large Files [original data]\n\n# 1.0 LIBRARIES ----\n\n# Tidyverse\nlibrary(tidyverse)\nlibrary(vroom)\n\n# Data Table\nlibrary(data.table)\n\n# 2.0 DATA IMPORT ----\n# Data is from April 22, 2024\n# Import files used:\n# g_assignee_disambiguated: Disambiguated assignee data for granted patents.\n# g_patent: Data on granted patents.\n# g_uspc_at_issue: USPC classification data for all granted patents at issue.\n\n# 2.1 Assignee Data ----\n\ncol_types_1 &lt;- list(\n  patent_id = col_character(),\n  assignee_sequence = col_skip(),\n  assignee_id = col_character(),\n  disambig_assignee_individual_name_first = col_character(),\n  disambig_assignee_individual_name_last = col_character(),\n  disambig_assignee_organization = col_character(),\n  assignee_type = col_double(),\n  location_id = col_skip()\n)\n\nassignee_data &lt;- vroom(\n  file       = \"~/GitHub/ss24-bdsb-Adrian-0402/source_data/wrangling_data/full_data/g_assignee_disambiguated.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_1,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# 2.2 Patent Data ----\n\ncol_types_2 &lt;- list(\n  patent_id = col_character(),\n  patent_type = col_skip(),\n  patent_date = col_date(\"%Y-%m-%d\"),\n  patent_title = col_character(),\n  patent_abstract = col_skip(),\n  wipo_kind = col_skip(),\n  num_claims = col_skip(),\n  withdrawn = col_skip(),\n  filename = col_skip()\n)\n\npatent_data &lt;- vroom(\n  file       = \"~/GitHub/ss24-bdsb-Adrian-0402/source_data/wrangling_data/full_data/g_patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_2,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# 2.3 USPC Data ----\n\ncol_types_3 &lt;- list(\n  patent_id = col_character(),\n  uspc_sequence = col_double(),\n  uspc_mainclass_id = col_character(),\n  uspc_mainclass_title = col_character(),\n  uspc_subclass_id = col_skip(),    #ignore since we only look at mainclasses\n  uspc_subclass_title = col_skip()\n)\n\nuspc_data &lt;- vroom(\n  file       = \"~/GitHub/ss24-bdsb-Adrian-0402/source_data/wrangling_data/full_data/g_uspc_at_issue.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types_3,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n# 3.0 TRANSFORM DATA ----\n\nsetDT(assignee_data)\nsetDT(patent_data)\nsetDT(uspc_data)\n\n# 4.0 DATA WRANGLING ----\n\n# 4.1 Joining / Merging Data ----\n\ncombined_patent_data &lt;- merge(assignee_data,patent_data,\n                              by = \"patent_id\",\n                              all.x = TRUE,\n                              all.y = FALSE)\n# free space\nrm(patent_data)\n\ncombined_uspc_data &lt;- merge(assignee_data,uspc_data,\n                            by = \"patent_id\",\n                            all.x = TRUE,\n                            all.y = FALSE)\n# Remove uncountable rows and free space\ncombined_uspc_data &lt;- combined_uspc_data[!is.na(uspc_mainclass_id)]\nrm(uspc_data)\n\n# 4.2 Set keys\n\nsetkey(assignee_data, \"assignee_id\")\nsetkey(combined_patent_data, \"assignee_id\")\nsetkey(combined_uspc_data, \"uspc_mainclass_id\")\n\n# 5.0 QUESTIONS ----\n\n# 5.1 Question 1: Patent Dominance: What US company / corporation has the most patents? \n#     List the 10 US companies with the most assigned/granted patents\n#     Important: Assignee type 2 filters by US companies\n\nquestion_1_dt &lt;- assignee_data[assignee_type == 2, .N , by = .(assignee_id,\n                                             disambig_assignee_organization)][order(-N)] %&gt;% \n  setnames(\"disambig_assignee_organization\",\"company\") %&gt;% \n  head(n = 10)\n\n# 5.2 Question 2: Recent patent activity: What US company had the most patents\n#     granted in 2019? List the top 10 companies with the most new granted \n#     patents for 2019. \n#     Also filter by type 2 for US companies.\n\nquestion_2_dt &lt;- \n  combined_patent_data[year(patent_date) == 2019 & assignee_type == 2, .N, by = .(assignee_id,\n                                                                                  disambig_assignee_organization)][order(-N)] %&gt;% \n  setnames(\"disambig_assignee_organization\",\"company\") %&gt;% \n  head(n = 10)\n\n# 5.3 Question 3: Innovation in Tech: What is the most innovative tech sector? \n#     For the top 10 companies (worldwide) with the most patents, \n#     what are the top 5 USPTO tech main classes?\n\n# Note top 10 companies (worldwide) first\ncompare_company &lt;- assignee_data[, .N, by = .(assignee_id)][order(-N),.(assignee_id)] %&gt;% \n  head(n = 10) %&gt;% \n  pull()\n\n# Subset all the patents for only the top 10 companies\n# Allow counting multiple uspc mainclasses for a patent, since subclasses would differ\nquestion_3_dt &lt;- \n  combined_uspc_data[assignee_id %in% compare_company, .N, by = .(uspc_mainclass_id,\n                                                                  uspc_mainclass_title)][order(-N)] %&gt;% \n  head(n = 5)\n\n\n2 Print Solutions\n\n# IBM has the most patents.\nquestion_1_dt\n\n\n\n  \n\n\n# IBM also had the most newly granted patents in 2019.\nquestion_2_dt\n\n\n\n  \n\n\n# Most innovative tech sector: ACTIVE SOLID-STATE DEVICES (E.G., TRANSISTORS, SOLID-STATE DIODES)\n# Top 5 main classes : 257, 438, 370, 430, 365 (considering only the top 10)\nquestion_3_dt"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "# Loading Libraries\nlibrary(tidyverse)\nlibrary(readxl)\n\n# Importing Files\nbikes_tbl &lt;- read_excel(\"~/GitHub/ss24-bdsb-Adrian-0402/content/01_journal/01_tidyverse_files/01_bike_sales/01_raw_data/bikes.xlsx\")\norderlines_tbl &lt;- read_excel(\"~/GitHub/ss24-bdsb-Adrian-0402/content/01_journal/01_tidyverse_files/01_bike_sales/01_raw_data/orderlines.xlsx\")\nbikeshops_tbl &lt;- read_excel(\"~/GitHub/ss24-bdsb-Adrian-0402/content/01_journal/01_tidyverse_files/01_bike_sales/01_raw_data/bikeshops.xlsx\")\n\n# Joining Data \nbike_orderlines_joined_tbl &lt;- orderlines_tbl %&gt;%\n  left_join(bikes_tbl, by = c(\"product.id\" = \"bike.id\")) %&gt;%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\n\n# Wrangling Data\nbike_orderlines_wrangled_tbl &lt;- bike_orderlines_joined_tbl %&gt;%\n  separate( col = location,\n            into = c(\"city\",\"state\"),\n            sep = \", \") %&gt;% \n  mutate(total.price = price * quantity) %&gt;% \n  select(-...1, -gender) %&gt;%\n  rename(bikeshop = name) %&gt;% \n  set_names(names(.) %&gt;% str_replace_all(\"\\\\.\", \"_\"))"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#by-location-state",
    "href": "content/01_journal/01_tidyverse.html#by-location-state",
    "title": "Tidyverse",
    "section": "\n2.1 By Location (State)",
    "text": "2.1 By Location (State)\n\n# Manipulate\nsales_by_state_tbl &lt;- bike_orderlines_wrangled_tbl %&gt;% \n  select(state, total_price) %&gt;% \n  group_by(state) %&gt;% \n  summarize(sales = sum(total_price)) %&gt;% \n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#Visualize\nsales_by_state_tbl %&gt;%\n  ggplot(aes(x = state, y = sales)) +\n  geom_col(fill = \"#16C17C\") +\n  geom_label(aes(label = sales_text)) +\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(\n    title    = \"Revenue by state\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\"\n  )\n\n\n\nRevenue by different states"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#by-location-state-and-year",
    "href": "content/01_journal/01_tidyverse.html#by-location-state-and-year",
    "title": "Tidyverse",
    "section": "\n2.2 By Location (State) and year",
    "text": "2.2 By Location (State) and year\n\n# Manipulate\nlibrary(lubridate)\n\nsales_by_state_year_tbl &lt;- bike_orderlines_wrangled_tbl %&gt;%\n  select(state, order_date, total_price) %&gt;% \n  mutate(year = year(order_date)) %&gt;% \n  group_by(year, state) %&gt;% \n  summarize(sales = sum(total_price)) %&gt;% \n  ungroup() %&gt;% \n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n# Visualize\nsales_by_state_year_tbl %&gt;%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  \n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n  \n  # Facet\n  facet_wrap(~ state) +\n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\",\n                                                    scale = 0.000001,\n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \"m €\")) +\n  labs(\n    title = \"Revenue by year and state\",\n    fill = \"States\" # Changes the legend name\n  )\n\n\n\nRevenue by different states and year"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "1 Getting some data through Spotify API\n\n#Spotify API\n\nlibrary(spotifyr) #install via devtools::install_github('charlie86/spotifyr')\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# can't use get_spotify_access_token() since function will prompt to website with \"Illegal scope\"\n# only way to bypass this broken API is to avoid certain scopes\nauth_object &lt;- get_spotify_authorization_code(scope = scopes()[c(7,8,9,10,14,15)])\n\n\ntop_tracks_tbl &lt;- get_my_top_artists_or_tracks(\n  type = \"tracks\",\n  limit = 20,\n  offset = 0,\n  time_range = \"medium_term\",\n  authorization = auth_object,\n  include_meta_info = FALSE\n) %&gt;% as_tibble()\n\n\ntop_tracks_wrangled_tbl &lt;- top_tracks_tbl %&gt;%\n  mutate(duration_min = duration((duration_ms / 1000),\"seconds\")) %&gt;% \n  select(artists,duration_min,name,popularity) %&gt;% \n  rename(track_name = name) %&gt;%\n  unnest(artists) %&gt;% \n  rename(artists = name) %&gt;%\n  select(artists,duration_min,track_name,popularity) %&gt;%\n  group_by(duration_min,track_name,popularity) %&gt;% \n  summarize(artists = paste(unique(artists), collapse = \", \")) %&gt;%\n  select(artists,track_name,duration_min,popularity) %&gt;% \n  arrange(desc(popularity))\n\ntop_tracks_wrangled_tbl %&gt;% \n  head(n = 10)\n\n\n# A tibble: 10 × 4\n# Groups:   duration_min, track_name [10]\n#  artists                      track_name         duration_min             popularity\n#  &lt;chr&gt;                        &lt;chr&gt;              &lt;Duration&gt;                    &lt;int&gt;\n#1 Kenya Grace                  Strangers          172.964s (~2.88 minutes)         88\n#2 Dynoro, Gigi D'Agostino      In My Mind         184.56s (~3.08 minutes)          80\n#3 Vicetone                     Walk Thru Fire     194.482s (~3.24 minutes)         66\n#4 deadmau5, Rob Swire          Ghosts 'n' Stuff   328.253s (~5.47 minutes)         56\n#5 Vini Vici, Ranji, Halflives  Everyday Rockstars 209.375s (~3.49 minutes)         41\n#6 Aether, Sizzle Bird, Veela   Raccoon City       226.925s (~3.78 minutes)         38\n#7 Bensley, Skyelle             All I Wanted       244.137s (~4.07 minutes)         35\n#8 Draper, Laura Brehm          Pressure           318.537s (~5.31 minutes)         35\n#9 Tut Tut Child, Danyka Nadeau Breathe            275.121s (~4.59 minutes)         31\n#10 Nomyn, Veela                Be Honest          223.655s (~3.73 minutes)         30\n\n\n2 Webscraping - RADON Bikes\n\n# Webscraping ----\n\n# 1.0 Libraries ----\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n# 1.1 Collect product categories ----\n\nurl_home &lt;- \"https://www.radon-bikes.de/en/\"\nhtml_home &lt;- read_html(url_home)\n\nbike_categories_chr &lt;- html_home %&gt;% \n  html_elements(css = \".megamenu__item a\") %&gt;% \n  html_attr('href') %&gt;% \n  str_subset(\"wear\", negate = TRUE) |&gt;\n  str_c(\"https://www.radon-bikes.de\",  ... = _) %&gt;% \n  paste(\"bikegrid/\", sep = \"\")\n  \n\n# 2.0 Collect bike data ----\n\nbike_category_url &lt;- bike_categories_chr[2]\nhtml_bike_category &lt;- bike_category_url %&gt;% \n  read_html()\n\nbike_url_chr &lt;- html_bike_category %&gt;% \n  html_elements(css = \".m-bikegrid__info a\") %&gt;% \n  html_attr('href') |&gt;\n  str_c(\"https://www.radon-bikes.de\",  ... = _)\n  \n\n# 2.1 Make a function ----\n\nget_bike_urls &lt;- function(url) {\n  \n  html_bike_category &lt;- read_html(url)\n  \n  bike_url_chr &lt;- html_bike_category %&gt;% \n    html_elements(css = \".m-bikegrid__info a\") %&gt;% \n    html_attr('href') |&gt;\n    str_c(\"https://www.radon-bikes.de\",  ... = _)\n  \n  return(bike_url_chr)\n}\n\n# Get all bike urls\nbike_urls_chr &lt;- map(bike_categories_chr,get_bike_urls)\n\n# 3.1 Subsetting ----\n\n# Unnest the mess into one column\nbike_urls_tbl &lt;- bike_urls_chr %&gt;% \n  as_tibble_col(column_name = \"url\") %&gt;% \n  unnest(cols = c(\"url\")) %&gt;% \n  unique() %&gt;% \n  tidyr::separate_wider_regex(cols = url, patterns = c(\".*de/en/\", family   = \"[^/]*\", \"/\",\n                                                       category = \"[^/]*\", \"/\",\n                                                       model    = \"[^/]*\", \"/\",\n                                                       \".*\"), cols_remove = F)\n\n# Select one category to analyze\nbike_urls_fullsuspension_tbl &lt;- bike_urls_tbl %&gt;% \n  filter(category == \"fullsuspension\")\n\n# 3.2 Get different data for 1 bike ----\n\nhtml_bike_model &lt;- read_html(bike_urls_fullsuspension_tbl$url[1])\n\nbike_model &lt;- html_bike_model %&gt;% \n  html_elements(css = \".m-bikedetail__overlays-top .a-heading--medium\") %&gt;% \n  html_text() %&gt;% \n  str_squish()\n\nbike_price &lt;- html_bike_model %&gt;% \n  html_elements(css = \".m-bikedetail__price--active\") %&gt;% \n  html_text() %&gt;% \n  .[1] %&gt;% \n  parse_number() %&gt;% \n  round()\n\nbike_weight &lt;- html_bike_model %&gt;% \n  html_elements(css = \".spec-42 .m-feature-list__description\") %&gt;% \n  html_text() %&gt;% \n  str_extract(\"[0-9]*[.,]*[0-9]*\")  %&gt;% \n  str_replace(\"\\\\,\",\"\\\\.\") %&gt;% \n  as.numeric()\n\n# 3.3 Make a function ----\n\nget_model_data &lt;- function(url) {\n  \n  html_bike_model &lt;- read_html(url)\n  \n  bike_model &lt;- html_bike_model %&gt;% \n    html_elements(css = \".m-bikedetail__overlays-top .a-heading--medium\") %&gt;% \n    html_text() %&gt;% \n    str_squish()\n  \n  bike_price &lt;- html_bike_model %&gt;% \n    html_elements(css = \".m-bikedetail__price--active\") %&gt;% \n    html_text() %&gt;% \n    .[1] %&gt;% \n    parse_number() %&gt;% \n    round()\n  \n  bike_weight &lt;- html_bike_model %&gt;% \n    html_elements(css = \".spec-42 .m-feature-list__description\") %&gt;% \n    html_text() %&gt;% \n    str_extract(\"[0-9]*[.,]*[0-9]*\")  %&gt;% \n    str_replace(\"\\\\,\",\"\\\\.\") %&gt;% \n    as.numeric()\n  \n  bike_data &lt;- tibble(url   = url,\n                      model = bike_model,\n                      price = bike_price,\n                      weight = bike_weight)\n  \n  return(bike_data)\n}\n\n# 3.4 Test functions ----\n\n# For one bike\n# bike_model_data_tbl &lt;- get_model_data(url = bike_urls_fullsuspension_tbl$url[1])\n\n# For one category\nbike_model_data_tbl &lt;- bike_urls_fullsuspension_tbl$url %&gt;% map_dfr(get_model_data)\n\n# For ALL categories\n# bike_model_data_tbl &lt;- bike_urls_tbl$url %&gt;% map_dfr(get_model_data)\n\n# 3.5 Join Data ----\n\n# For one category\nbike_model_data_joined_tbl &lt;- bike_urls_fullsuspension_tbl %&gt;% \n  left_join(bike_model_data_tbl, by = join_by(\"url\"))\n\n# For ALL categories\n# bike_model_data_joined_tbl &lt;- bike_urls_tbl %&gt;% \n#  left_join(bike_model_data_tbl, by = join_by(\"url\"))\n\n# 4 Print for category \"fullsuspension\"\n\nbike_model_data_joined_tbl %&gt;% \n  head(n = 10)\n\n\n\n  \n\n\n# A tibble: 10 × 7\n#   family       category       model.x        url                        model.y price weight\n#   &lt;chr&gt;        &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                      &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#1  mountainbike fullsuspension skeen-trail-al https://www.radon-bikes.d… SKEEN …  1428   14.4\n#2  mountainbike fullsuspension skeen-trail-al https://www.radon-bikes.d… SKEEN …  1680   14.4\n#3  mountainbike fullsuspension skeen-trail    https://www.radon-bikes.d… SKEEN …  1848   13.4\n#4  mountainbike fullsuspension skeen-trail    https://www.radon-bikes.d… SKEEN …  2184   13.2\n#5  mountainbike fullsuspension skeen-trail    https://www.radon-bikes.d… SKEEN …  2688   13.8\n#6  mountainbike fullsuspension slide-trail-al https://www.radon-bikes.d… SLIDE …  1848   14.9\n#7  mountainbike fullsuspension slide-trail-al https://www.radon-bikes.d… SLIDE …  2268   15.0\n#8  mountainbike fullsuspension slide-trail-al https://www.radon-bikes.d… SLIDE …  1512   14.7\n#9  mountainbike fullsuspension slide-trail-al https://www.radon-bikes.d… SLIDE …  1764   15.1\n#10 mountainbike fullsuspension slide-trail    https://www.radon-bikes.d… SLIDE …  4033   14.0"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "1 Cumulative COVID-19 Cases\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggthemes)\n\ncovid_data_tbl &lt;- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n# 1.0 Data Manipulation ----\n\nfilter_countries &lt;- c(\"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\")\n\ncovid_cum_cases &lt;- covid_data_tbl %&gt;% \n  select(location, date, total_cases) %&gt;% \n  filter(location %in% filter_countries,\n         year(date) &lt; 2022 |\n         year(date) == 2022 & month(date) &lt; 5 & day(date) &lt;= 19) %&gt;% \n  mutate(across(total_cases, ~replace_na(., 0))) %&gt;% \n  mutate(label_text = scales::number(total_cases,\n                                     big.mark = \".\"))\n\neurope_cases &lt;- covid_data_tbl %&gt;% \n  select(continent,date,total_cases) %&gt;% \n  filter(continent == \"Europe\",\n         year(date) &lt; 2022 |\n         year(date) == 2022 & month(date) &lt; 5 & day(date) &lt;= 19) %&gt;% \n  mutate(across(total_cases, ~replace_na(., 0))) %&gt;%\n  group_by(continent,date) %&gt;% \n  summarize(total_cases = sum(total_cases)) %&gt;% \n  mutate(label_text_E = scales::number(total_cases,\n                                     big.mark = \".\"))\n\ncustom_label_country &lt;- covid_cum_cases %&gt;% \n  filter(date == \"2022-04-19\" & location == \"United States\")\n\ncustom_label_europe &lt;- europe_cases %&gt;% \n  filter(date == \"2022-04-19\")\n\n# 2.0 Data Visualization ----\n\ncovid_cum_cases %&gt;%\n  \n  ggplot(aes(date, total_cases, color = location)) +\n  \n  # Geometries\n  geom_smooth(method = \"loess\", span = 0.05, size = 0.7) +\n  geom_smooth(data = europe_cases, aes(color = continent), method = \"loess\", span = 0.05, size = 0.7) +\n  geom_label(data = custom_label_country, aes(label = label_text),\n             nudge_x = -80, show.legend = FALSE) +\n  geom_label(data = custom_label_europe, aes(label = label_text_E, color = continent),\n             nudge_x = -100, nudge_y = -30, show.legend = FALSE) + \n  \n  # Scales\n  scale_y_continuous(labels = scales::number_format(scale = 1/1e6,\n                                                    suffix = \"M\")) +\n  scale_x_date(breaks = \"1 month\",date_labels = \"%B '%y\", position = \"bottom\") +\n  \n  # Themes\n  theme_dark() + \n  scale_color_viridis_d(option = \"H\") + \n\n  theme(\n    axis.text.x = element_text(\n      angle = 45,\n      hjust = 1\n    ),\n    legend.position = \"bottom\") +\n  \n  guides(color = guide_legend(nrow = 2)) +\n\n  # Labels\n  labs(\n  title = \"COVID-19 confirmed cases worldwide\",\n  subtitle = \"As of 19/04/2022\",\n  x = \"\",\n  y = \"Cumulative Cases\",\n  color = \"Continent / Country\"\n  )"
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  }
]